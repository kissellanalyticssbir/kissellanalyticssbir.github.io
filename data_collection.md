## Data Collection

The sbir awards are federally funded, and thus the data are publicly available. While the SBIR website has an API for downloading data, there are some technical restrictions that make it difficult to collect all data from the site. As such, I wrote a web scraper that first collected the links to every award from the department of defense (see Appendix A). I then wrote a second scraper to iterate through the list and collect all available data related to each award (see Appendix B). The data for each company that received at least one award was also available. This policies around this data were less restrictive, and thus I was able to write a much simpler program which collected that data from the API (see Appendix C)

I first cleaned each variable and converted them to the appropriate data types. As the phase variable was predicted to be a relevant factor, I recoded the variable to be more informative by forming 4 levels. Phase 1a contained awards that were in phase I, but never reached phase II. Phase 1b contained awards that were in phase I, and did reach phase II. Phase 2a contained awards that were in phase II, and had started in phase I. Lastly, Phase 2b contained awards in Phase II, but were never in phase I. I also wrote a python program to extract a number of features from the text (see Appendix E). These features included character and word count for award titles, and character count, word count, sentence count, syllable count, number of proper nouns, number of nouns, number of verbs, and five measures of reading level (i.e., Dalechall, Flesch, Fleshkincaid, Gunningfog, and Smog) for all text (i.e., title and abstract combined).
